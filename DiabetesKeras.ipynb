{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XdNlr5jSYWik","outputId":"33c4deba-2034-4a5f-d28e-cb54c411fe6c","executionInfo":{"status":"ok","timestamp":1678918188456,"user_tz":300,"elapsed":1175,"user":{"displayName":"Lnu Rumana Thaskeen","userId":"01255255793086056946"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"]}],"source":["from google.colab import drive \n","drive.mount('/content/gdrive') "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_r3MUyfgE-IQ"},"outputs":[],"source":["path_to_csv = '/content/gdrive/My Drive/diabetes.csv'"]},{"cell_type":"markdown","metadata":{"id":"oh2yYnM0Dsz7"},"source":["# 1. Using the use case in class\n"]},{"cell_type":"code","execution_count":59,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iuzHorBiDciq","outputId":"5f2d30ff-07f6-443f-9077-40c4ba9fa59d","executionInfo":{"status":"ok","timestamp":1678922578845,"user_tz":300,"elapsed":6951,"user":{"displayName":"Lnu Rumana Thaskeen","userId":"01255255793086056946"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","18/18 [==============================] - 0s 2ms/step - loss: 15.1124 - acc: 0.6580\n","Epoch 2/100\n","18/18 [==============================] - 0s 2ms/step - loss: 5.5967 - acc: 0.6111\n","Epoch 3/100\n","18/18 [==============================] - 0s 2ms/step - loss: 3.3545 - acc: 0.5260\n","Epoch 4/100\n","18/18 [==============================] - 0s 2ms/step - loss: 2.4319 - acc: 0.5677\n","Epoch 5/100\n","18/18 [==============================] - 0s 2ms/step - loss: 1.9134 - acc: 0.5573\n","Epoch 6/100\n","18/18 [==============================] - 0s 2ms/step - loss: 1.5842 - acc: 0.6076\n","Epoch 7/100\n","18/18 [==============================] - 0s 2ms/step - loss: 1.3428 - acc: 0.6267\n","Epoch 8/100\n","18/18 [==============================] - 0s 2ms/step - loss: 1.1783 - acc: 0.6285\n","Epoch 9/100\n","18/18 [==============================] - 0s 4ms/step - loss: 1.0789 - acc: 0.6406\n","Epoch 10/100\n","18/18 [==============================] - 0s 3ms/step - loss: 1.0179 - acc: 0.6389\n","Epoch 11/100\n","18/18 [==============================] - 0s 4ms/step - loss: 0.9806 - acc: 0.6736\n","Epoch 12/100\n","18/18 [==============================] - 0s 4ms/step - loss: 0.9363 - acc: 0.6562\n","Epoch 13/100\n","18/18 [==============================] - 0s 3ms/step - loss: 0.8840 - acc: 0.6684\n","Epoch 14/100\n","18/18 [==============================] - 0s 8ms/step - loss: 0.8918 - acc: 0.6701\n","Epoch 15/100\n","18/18 [==============================] - 0s 6ms/step - loss: 0.8403 - acc: 0.6719\n","Epoch 16/100\n","18/18 [==============================] - 0s 6ms/step - loss: 0.8404 - acc: 0.6632\n","Epoch 17/100\n","18/18 [==============================] - 0s 6ms/step - loss: 0.8704 - acc: 0.6580\n","Epoch 18/100\n","18/18 [==============================] - 0s 5ms/step - loss: 0.8145 - acc: 0.6788\n","Epoch 19/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.8000 - acc: 0.6840\n","Epoch 20/100\n","18/18 [==============================] - 0s 3ms/step - loss: 0.7983 - acc: 0.6927\n","Epoch 21/100\n","18/18 [==============================] - 0s 3ms/step - loss: 0.7921 - acc: 0.6823\n","Epoch 22/100\n","18/18 [==============================] - 0s 8ms/step - loss: 0.7522 - acc: 0.6979\n","Epoch 23/100\n","18/18 [==============================] - 0s 4ms/step - loss: 0.7271 - acc: 0.7066\n","Epoch 24/100\n","18/18 [==============================] - 0s 4ms/step - loss: 0.7622 - acc: 0.6806\n","Epoch 25/100\n","18/18 [==============================] - 0s 4ms/step - loss: 0.7474 - acc: 0.6962\n","Epoch 26/100\n","18/18 [==============================] - 0s 5ms/step - loss: 0.7199 - acc: 0.6875\n","Epoch 27/100\n","18/18 [==============================] - 0s 5ms/step - loss: 0.7299 - acc: 0.7014\n","Epoch 28/100\n","18/18 [==============================] - 0s 4ms/step - loss: 0.7122 - acc: 0.6840\n","Epoch 29/100\n","18/18 [==============================] - 0s 6ms/step - loss: 0.7430 - acc: 0.6962\n","Epoch 30/100\n","18/18 [==============================] - 0s 3ms/step - loss: 0.7006 - acc: 0.6962\n","Epoch 31/100\n","18/18 [==============================] - 0s 1ms/step - loss: 0.7414 - acc: 0.6823\n","Epoch 32/100\n","18/18 [==============================] - 0s 1ms/step - loss: 0.7003 - acc: 0.7083\n","Epoch 33/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.6797 - acc: 0.6997\n","Epoch 34/100\n","18/18 [==============================] - 0s 1ms/step - loss: 0.6518 - acc: 0.7118\n","Epoch 35/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.6858 - acc: 0.6910\n","Epoch 36/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.7312 - acc: 0.6892\n","Epoch 37/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.6901 - acc: 0.6840\n","Epoch 38/100\n","18/18 [==============================] - 0s 3ms/step - loss: 0.6621 - acc: 0.7083\n","Epoch 39/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.6714 - acc: 0.7049\n","Epoch 40/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.6376 - acc: 0.7118\n","Epoch 41/100\n","18/18 [==============================] - 0s 3ms/step - loss: 0.6371 - acc: 0.7031\n","Epoch 42/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.6586 - acc: 0.7083\n","Epoch 43/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.6268 - acc: 0.7205\n","Epoch 44/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.6175 - acc: 0.7083\n","Epoch 45/100\n","18/18 [==============================] - 0s 3ms/step - loss: 0.6387 - acc: 0.7101\n","Epoch 46/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.6435 - acc: 0.7101\n","Epoch 47/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.6243 - acc: 0.7292\n","Epoch 48/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.6612 - acc: 0.6962\n","Epoch 49/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.6294 - acc: 0.6875\n","Epoch 50/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.6370 - acc: 0.6997\n","Epoch 51/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.6297 - acc: 0.6979\n","Epoch 52/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.6037 - acc: 0.7153\n","Epoch 53/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.5968 - acc: 0.7153\n","Epoch 54/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.6134 - acc: 0.7101\n","Epoch 55/100\n","18/18 [==============================] - 0s 3ms/step - loss: 0.6215 - acc: 0.7326\n","Epoch 56/100\n","18/18 [==============================] - 0s 1ms/step - loss: 0.6199 - acc: 0.6667\n","Epoch 57/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.5985 - acc: 0.7135\n","Epoch 58/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.5870 - acc: 0.7101\n","Epoch 59/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.6320 - acc: 0.7014\n","Epoch 60/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.6317 - acc: 0.6997\n","Epoch 61/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.6438 - acc: 0.7014\n","Epoch 62/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.6427 - acc: 0.6858\n","Epoch 63/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.6122 - acc: 0.7222\n","Epoch 64/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.5784 - acc: 0.7292\n","Epoch 65/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.5837 - acc: 0.7066\n","Epoch 66/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.5749 - acc: 0.7309\n","Epoch 67/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.5746 - acc: 0.7274\n","Epoch 68/100\n","18/18 [==============================] - 0s 4ms/step - loss: 0.5885 - acc: 0.7257\n","Epoch 69/100\n","18/18 [==============================] - 0s 3ms/step - loss: 0.5733 - acc: 0.7274\n","Epoch 70/100\n","18/18 [==============================] - 0s 3ms/step - loss: 0.5688 - acc: 0.7483\n","Epoch 71/100\n","18/18 [==============================] - 0s 4ms/step - loss: 0.5760 - acc: 0.7361\n","Epoch 72/100\n","18/18 [==============================] - 0s 3ms/step - loss: 0.5725 - acc: 0.7049\n","Epoch 73/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.5829 - acc: 0.7205\n","Epoch 74/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.5708 - acc: 0.7309\n","Epoch 75/100\n","18/18 [==============================] - 0s 3ms/step - loss: 0.5727 - acc: 0.7240\n","Epoch 76/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.5742 - acc: 0.7344\n","Epoch 77/100\n","18/18 [==============================] - 0s 3ms/step - loss: 0.5788 - acc: 0.7135\n","Epoch 78/100\n","18/18 [==============================] - 0s 3ms/step - loss: 0.5752 - acc: 0.7083\n","Epoch 79/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.5560 - acc: 0.7431\n","Epoch 80/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.5609 - acc: 0.7205\n","Epoch 81/100\n","18/18 [==============================] - 0s 3ms/step - loss: 0.5643 - acc: 0.7344\n","Epoch 82/100\n","18/18 [==============================] - 0s 4ms/step - loss: 0.5620 - acc: 0.7326\n","Epoch 83/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.5509 - acc: 0.7344\n","Epoch 84/100\n","18/18 [==============================] - 0s 3ms/step - loss: 0.5660 - acc: 0.7396\n","Epoch 85/100\n","18/18 [==============================] - 0s 3ms/step - loss: 0.5671 - acc: 0.7413\n","Epoch 86/100\n","18/18 [==============================] - 0s 3ms/step - loss: 0.6017 - acc: 0.6927\n","Epoch 87/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.5886 - acc: 0.7309\n","Epoch 88/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.5635 - acc: 0.7205\n","Epoch 89/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.5649 - acc: 0.7274\n","Epoch 90/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.5483 - acc: 0.7292\n","Epoch 91/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.6072 - acc: 0.7170\n","Epoch 92/100\n","18/18 [==============================] - 0s 3ms/step - loss: 0.5747 - acc: 0.7188\n","Epoch 93/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.5594 - acc: 0.7205\n","Epoch 94/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.5462 - acc: 0.7396\n","Epoch 95/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.5457 - acc: 0.7517\n","Epoch 96/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.5625 - acc: 0.7153\n","Epoch 97/100\n","18/18 [==============================] - 0s 3ms/step - loss: 0.5590 - acc: 0.7274\n","Epoch 98/100\n","18/18 [==============================] - 0s 4ms/step - loss: 0.5568 - acc: 0.7240\n","Epoch 99/100\n","18/18 [==============================] - 0s 4ms/step - loss: 0.5519 - acc: 0.7431\n","Epoch 100/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.5536 - acc: 0.7257\n","Model: \"sequential_8\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_26 (Dense)            (None, 20)                180       \n","                                                                 \n"," dense_27 (Dense)            (None, 1)                 21        \n","                                                                 \n","=================================================================\n","Total params: 201\n","Trainable params: 201\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","6/6 [==============================] - 0s 3ms/step - loss: 0.6981 - acc: 0.6302\n","[0.6981412768363953, 0.6302083134651184]\n"]}],"source":["import keras\n","import pandas\n","from keras.models import Sequential\n","from keras.layers.core import Dense, Activation\n","\n","# load dataset\n","from sklearn.model_selection import train_test_split\n","import pandas as pd\n","import numpy as np\n","\n","dataset = pd.read_csv(path_to_csv, header=None).values\n","\n","X_train, X_test, Y_train, Y_test = train_test_split(dataset[:,0:8], dataset[:,8],\n","                                                    test_size=0.25, random_state=87)\n","np.random.seed(155)\n","my_first_nn = Sequential() # create model\n","my_first_nn.add(Dense(20, input_dim=8, activation='relu')) # hidden layer\n","my_first_nn.add(Dense(1, activation='sigmoid')) # output layer\n","my_first_nn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n","my_first_nn_fitted = my_first_nn.fit(X_train, Y_train, epochs=100,\n","                                     initial_epoch=0)\n","print(my_first_nn.summary())\n","print(my_first_nn.evaluate(X_test, Y_test))"]},{"cell_type":"markdown","source":["# a. Add more Dense layers to the existing code and check how the accuracy changes\n"],"metadata":{"id":"3YPG96X1zQEE"}},{"cell_type":"code","source":["my_first_nn = Sequential() # create model\n","my_first_nn.add(Dense(20, input_dim=8, activation='relu')) # hidden layer with input\n","my_first_nn.add(Dense(20, activation='relu')) # hidden layer\n","my_first_nn.add(Dense(20, activation='relu')) # hidden layer\n","my_first_nn.add(Dense(1, activation='sigmoid')) # output layer\n","my_first_nn.compile(loss='binary_crossentropy', optimizer='adam',metrics=['acc']) # compilation\n","my_first_nn_fitted = my_first_nn.fit(X_train, Y_train, epochs=100,verbose=0, initial_epoch=0) # Training\n","print(my_first_nn.summary()) #Summary\n","print(my_first_nn.evaluate(X_test, Y_test)) #Evaluating"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o8eHXqoKzijD","executionInfo":{"status":"ok","timestamp":1678922600504,"user_tz":300,"elapsed":6869,"user":{"displayName":"Lnu Rumana Thaskeen","userId":"01255255793086056946"}},"outputId":"f785e592-1e61-4a18-891c-5af7418eea09"},"execution_count":60,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_9\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_28 (Dense)            (None, 20)                180       \n","                                                                 \n"," dense_29 (Dense)            (None, 20)                420       \n","                                                                 \n"," dense_30 (Dense)            (None, 20)                420       \n","                                                                 \n"," dense_31 (Dense)            (None, 1)                 21        \n","                                                                 \n","=================================================================\n","Total params: 1,041\n","Trainable params: 1,041\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","6/6 [==============================] - 0s 3ms/step - loss: 0.5584 - acc: 0.6979\n","[0.5583901405334473, 0.6979166865348816]\n"]}]},{"cell_type":"code","source":["my_first_nn = Sequential() # create model\n","my_first_nn.add(Dense(20, input_dim=8, activation='relu')) # hidden layer with input\n","my_first_nn.add(Dense(22, activation='relu')) # hidden layer\n","my_first_nn.add(Dense(24, activation='relu')) # hidden layer\n","my_first_nn.add(Dense(1, activation='sigmoid')) # output layer\n","my_first_nn.compile(loss='binary_crossentropy', optimizer='adam',metrics=['acc']) # compilation\n","my_first_nn_fitted = my_first_nn.fit(X_train, Y_train, epochs=100,verbose=0, initial_epoch=0) # Training\n","print(my_first_nn.summary()) #Summary\n","print(my_first_nn.evaluate(X_test, Y_test)) #Evaluating"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"luKaiGerzzBk","executionInfo":{"status":"ok","timestamp":1678922643827,"user_tz":300,"elapsed":4086,"user":{"displayName":"Lnu Rumana Thaskeen","userId":"01255255793086056946"}},"outputId":"540da354-e43f-48bb-c412-2e301dfbdf26"},"execution_count":61,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_10\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_32 (Dense)            (None, 20)                180       \n","                                                                 \n"," dense_33 (Dense)            (None, 22)                462       \n","                                                                 \n"," dense_34 (Dense)            (None, 24)                552       \n","                                                                 \n"," dense_35 (Dense)            (None, 1)                 25        \n","                                                                 \n","=================================================================\n","Total params: 1,219\n","Trainable params: 1,219\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","6/6 [==============================] - 0s 3ms/step - loss: 0.6171 - acc: 0.6823\n","[0.6171173453330994, 0.6822916865348816]\n"]}]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"}},"nbformat":4,"nbformat_minor":0}
